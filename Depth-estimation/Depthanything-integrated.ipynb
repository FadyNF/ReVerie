{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "087a720a",
   "metadata": {},
   "source": [
    "# Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bdf32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"SUPABASE_URL\"] = \"https://viqawhbbhlkbjxntmwpn.supabase.co\"\n",
    "os.environ[\"SUPABASE_SERVICE_ROLE_KEY\"] = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InZpcWF3aGJiaGxrYmp4bnRtd3BuIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTc2OTYzNjEwMywiZXhwIjoyMDg1MjEyMTAzfQ.DvUNXsw8gwdxhiG71QPYNVFhQIYRcDQuP9QC2VOiCu0\"  # backend-only\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7537cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK URL: https://viqawhbbhlkbjxntmwpn.supabase.co/\n",
      "OK client: https://viqawhbbhlkbjxntmwpn.supabase.co/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from supabase import create_client\n",
    "\n",
    "# 1) Force trailing slash\n",
    "os.environ[\"SUPABASE_URL\"] = os.environ[\"SUPABASE_URL\"].strip()\n",
    "if not os.environ[\"SUPABASE_URL\"].endswith(\"/\"):\n",
    "    os.environ[\"SUPABASE_URL\"] += \"/\"\n",
    "\n",
    "# 2) Recreate client AFTER fixing\n",
    "supabase = create_client(os.environ[\"SUPABASE_URL\"], os.environ[\"SUPABASE_SERVICE_ROLE_KEY\"])\n",
    "\n",
    "print(\"OK URL:\", os.environ[\"SUPABASE_URL\"])\n",
    "print(\"OK client:\", supabase.supabase_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792f81d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK DB: scene_runs + pipeline_outputs exist\n"
     ]
    }
   ],
   "source": [
    "# Check DB tables exist\n",
    "try:\n",
    "    r = supabase.table(\"scene_runs\").select(\"id\").limit(1).execute()\n",
    "    r2 = supabase.table(\"pipeline_outputs\").select(\"id\").limit(1).execute()\n",
    "    print(\"OK DB: scene_runs + pipeline_outputs exist\")\n",
    "except Exception as e:\n",
    "    print(\"DB FAIL:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aadf19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK Storage upload: runs/_debug/test.txt\n"
     ]
    }
   ],
   "source": [
    "BUCKET = \"Pipeline\"\n",
    "\n",
    "test_path = \"runs/_debug/test.txt\"\n",
    "content = b\"hello supabase\"\n",
    "\n",
    "supabase.storage.from_(BUCKET).upload(\n",
    "    path=test_path,\n",
    "    file=content,\n",
    "    file_options={\"content-type\":\"text/plain\",\"upsert\":\"true\"}\n",
    ")\n",
    "\n",
    "print(\"OK Storage upload:\", test_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3515034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK run_id: aea38f28-476b-4d89-8cc7-707b83611ef3\n",
      "OK storage input upload: runs/aea38f28-476b-4d89-8cc7-707b83611ef3/input/original.jpg\n",
      "OK DB row upserted for input\n"
     ]
    }
   ],
   "source": [
    "import cv2, os\n",
    "\n",
    "BUCKET = \"Pipeline\"\n",
    "\n",
    "IMG_PATH = \"/content/drive/MyDrive/Depthanythingv2/data/eval/402db54d-53c8-4392-a5dc-b2e5fb6c337a.jpg\"\n",
    "\n",
    "# 1) Create run\n",
    "run = supabase.table(\"scene_runs\").insert({\n",
    "    \"scene_name\": \"debug_depth_run\",\n",
    "    \"notes\": \"step4: input upload only\"\n",
    "}).execute()\n",
    "\n",
    "run_id = run.data[0][\"id\"]\n",
    "print(\"OK run_id:\", run_id)\n",
    "\n",
    "# 2) Read image\n",
    "img = cv2.imread(IMG_PATH)\n",
    "if img is None:\n",
    "    raise ValueError(\"Image not found/readable: \" + IMG_PATH)\n",
    "\n",
    "# 3) Upload image to storage under run folder\n",
    "input_path = f\"runs/{run_id}/input/original.jpg\"\n",
    "\n",
    "ok, buf = cv2.imencode(\".jpg\", img, [int(cv2.IMWRITE_JPEG_QUALITY), 95])\n",
    "if not ok:\n",
    "    raise RuntimeError(\"JPEG encode failed\")\n",
    "\n",
    "supabase.storage.from_(BUCKET).upload(\n",
    "    path=input_path,\n",
    "    file=buf.tobytes(),\n",
    "    file_options={\"content-type\":\"image/jpeg\",\"upsert\":\"true\"}\n",
    ")\n",
    "print(\"OK storage input upload:\", input_path)\n",
    "\n",
    "# 4) Upsert DB row in pipeline_outputs\n",
    "h, w = img.shape[:2]\n",
    "row = {\n",
    "    \"run_id\": run_id,\n",
    "    \"stage\": \"input\",\n",
    "    \"file_role\": \"original_image\",\n",
    "    \"bucket\": BUCKET,\n",
    "    \"path\": input_path,\n",
    "    \"mime_type\": \"image/jpeg\",\n",
    "    \"meta\": {\"width\": w, \"height\": h, \"source\": \"colab_step4\"}\n",
    "}\n",
    "supabase.table(\"pipeline_outputs\").upsert(row).execute()\n",
    "\n",
    "print(\"OK DB row upserted for input\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431dc410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "letterbox: False\n",
      "unletterbox: False\n",
      "infer_tta_rel: False\n",
      "to_u16_rel: False\n"
     ]
    }
   ],
   "source": [
    "print(\"letterbox:\", \"letterbox\" in globals())\n",
    "print(\"unletterbox:\", \"unletterbox\" in globals())\n",
    "print(\"infer_tta_rel:\", \"infer_tta_rel\" in globals())\n",
    "print(\"to_u16_rel:\", \"to_u16_rel\" in globals())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b90ac0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb383495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK model loaded on cuda\n",
      "OK helpers defined: letterbox/unletterbox/infer_tta_rel/to_u16_rel\n"
     ]
    }
   ],
   "source": [
    "import os, sys, cv2, numpy as np, torch\n",
    "\n",
    "# --- paths: update if yours differ ---\n",
    "REPO = \"/content/drive/MyDrive/Depthanythingv2\"\n",
    "CKPT = f\"{REPO}/checkpoints/depth_anything_v2_vitl.pth\"\n",
    "\n",
    "# Make sure we can import the library\n",
    "if REPO not in sys.path:\n",
    "    sys.path.append(REPO)\n",
    "\n",
    "from depth_anything_v2.dpt import DepthAnythingV2\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# vitl config\n",
    "model = DepthAnythingV2(encoder=\"vitl\", features=256, out_channels=[256, 512, 1024, 1024])\n",
    "state = torch.load(CKPT, map_location=\"cpu\")\n",
    "model.load_state_dict(state, strict=True)\n",
    "model = model.to(DEVICE).eval()\n",
    "print(\"OK model loaded on\", DEVICE)\n",
    "\n",
    "# ---- required helpers ----\n",
    "def letterbox(img, target=896):\n",
    "    h, w = img.shape[:2]\n",
    "    s = target / max(h, w)\n",
    "    nh, nw = int(round(h * s)), int(round(w * s))\n",
    "    img_r = cv2.resize(img, (nw, nh), interpolation=cv2.INTER_CUBIC)\n",
    "    top = (target - nh) // 2; bottom = target - nh - top\n",
    "    left = (target - nw) // 2; right = target - nw - left\n",
    "    img_p = cv2.copyMakeBorder(img_r, top, bottom, left, right,\n",
    "                               cv2.BORDER_CONSTANT, value=(0, 0, 0))\n",
    "    return img_p, (top, bottom, left, right), (h, w)\n",
    "\n",
    "def unletterbox(arr, pads, orig_hw):\n",
    "    top, bottom, left, right = pads\n",
    "    arr = arr[top:arr.shape[0]-bottom, left:arr.shape[1]-right]\n",
    "    return cv2.resize(arr, (orig_hw[1], orig_hw[0]), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "@torch.no_grad()\n",
    "def infer_tta_rel(img_bgr):\n",
    "    # Predict and average normal + flipped; keep float32\n",
    "    d0 = model.infer_image(img_bgr).astype(np.float32)\n",
    "    d1 = model.infer_image(cv2.flip(img_bgr, 1)).astype(np.float32)\n",
    "    d1 = np.flip(d1, axis=1)\n",
    "    return (0.5 * (d0 + d1)).astype(np.float32)\n",
    "\n",
    "def to_u16_rel(depth):\n",
    "    d = depth.astype(np.float32)\n",
    "    d = np.nan_to_num(d, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    if (d > 0).sum() < 10:\n",
    "        return np.zeros_like(d, dtype=np.uint16)\n",
    "    p1, p99 = np.percentile(d[d > 0], (1, 99))\n",
    "    p1 = np.float32(p1); p99 = np.float32(p99)\n",
    "    d = np.clip(d, p1, p99)\n",
    "    d = (d - p1) / max(np.float32(1e-6), (p99 - p1))\n",
    "    d = np.clip(d, np.float32(1e-6), np.float32(1.0))\n",
    "    return (d * np.float32(65535.0)).astype(np.uint16)\n",
    "\n",
    "print(\"OK helpers defined: letterbox/unletterbox/infer_tta_rel/to_u16_rel\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fc21f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK run_id: 13a3f2a8-a2f7-4b2f-95ff-f08d662f357e\n",
      "OK input stored + DB row\n",
      "OK depth inferred\n",
      "OK depth outputs uploaded + DB rows\n",
      "RUN DONE: 13a3f2a8-a2f7-4b2f-95ff-f08d662f357e\n",
      "Input: runs/13a3f2a8-a2f7-4b2f-95ff-f08d662f357e/input/original.jpg\n",
      "Depth PNG: runs/13a3f2a8-a2f7-4b2f-95ff-f08d662f357e/depth/depth_rel_u16.png\n",
      "Depth Viz: runs/13a3f2a8-a2f7-4b2f-95ff-f08d662f357e/depth/depth_viz.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2, numpy as np\n",
    "\n",
    "BUCKET = \"Pipeline\"\n",
    "IMG_PATH = \"/content/drive/MyDrive/Depthanythingv2/data/eval/c2dfaff7-cab9-4f3c-9a83-71d88d36526c.JPG\"\n",
    "\n",
    "# 1) Create run\n",
    "run = supabase.table(\"scene_runs\").insert({\n",
    "    \"scene_name\": \"depth_trial\",\n",
    "    \"notes\": \"step5: depth infer + upload\"\n",
    "}).execute()\n",
    "run_id = run.data[0][\"id\"]\n",
    "print(\"OK run_id:\", run_id)\n",
    "\n",
    "# 2) Read image\n",
    "img = cv2.imread(IMG_PATH)\n",
    "if img is None:\n",
    "    raise ValueError(\"Image not found/readable: \" + IMG_PATH)\n",
    "h, w = img.shape[:2]\n",
    "\n",
    "# 3) Upload input\n",
    "input_path = f\"runs/{run_id}/input/original.jpg\"\n",
    "ok, buf = cv2.imencode(\".jpg\", img, [int(cv2.IMWRITE_JPEG_QUALITY), 95])\n",
    "if not ok:\n",
    "    raise RuntimeError(\"JPEG encode failed\")\n",
    "\n",
    "supabase.storage.from_(BUCKET).upload(\n",
    "    path=input_path,\n",
    "    file=buf.tobytes(),\n",
    "    file_options={\"content-type\":\"image/jpeg\",\"upsert\":\"true\"}\n",
    ")\n",
    "\n",
    "supabase.table(\"pipeline_outputs\").upsert({\n",
    "    \"run_id\": run_id,\n",
    "    \"stage\": \"input\",\n",
    "    \"file_role\": \"original_image\",\n",
    "    \"bucket\": BUCKET,\n",
    "    \"path\": input_path,\n",
    "    \"mime_type\": \"image/jpeg\",\n",
    "    \"meta\": {\"width\": w, \"height\": h}\n",
    "}).execute()\n",
    "print(\"OK input stored + DB row\")\n",
    "\n",
    "# 4) Depth inference\n",
    "img_p, pads, orig_hw = letterbox(img, 896)\n",
    "depth_rel_p = infer_tta_rel(img_p)\n",
    "depth_rel = unletterbox(depth_rel_p, pads, orig_hw).astype(np.float32)\n",
    "\n",
    "rel16 = to_u16_rel(depth_rel)\n",
    "viz = cv2.applyColorMap(255 - (rel16 // 256).astype(np.uint8), cv2.COLORMAP_INFERNO)\n",
    "print(\"OK depth inferred\")\n",
    "\n",
    "# 5) Upload depth outputs\n",
    "depth_png_path = f\"runs/{run_id}/depth/depth_rel_u16.png\"\n",
    "depth_viz_path = f\"runs/{run_id}/depth/depth_viz.jpg\"\n",
    "\n",
    "ok, buf_png = cv2.imencode(\".png\", rel16)\n",
    "if not ok:\n",
    "    raise RuntimeError(\"Depth PNG encode failed\")\n",
    "ok, buf_viz = cv2.imencode(\".jpg\", viz, [int(cv2.IMWRITE_JPEG_QUALITY), 92])\n",
    "if not ok:\n",
    "    raise RuntimeError(\"Viz JPG encode failed\")\n",
    "\n",
    "supabase.storage.from_(BUCKET).upload(\n",
    "    path=depth_png_path,\n",
    "    file=buf_png.tobytes(),\n",
    "    file_options={\"content-type\":\"image/png\",\"upsert\":\"true\"}\n",
    ")\n",
    "supabase.storage.from_(BUCKET).upload(\n",
    "    path=depth_viz_path,\n",
    "    file=buf_viz.tobytes(),\n",
    "    file_options={\"content-type\":\"image/jpeg\",\"upsert\":\"true\"}\n",
    ")\n",
    "\n",
    "# 6) DB upserts for outputs\n",
    "supabase.table(\"pipeline_outputs\").upsert({\n",
    "    \"run_id\": run_id,\n",
    "    \"stage\": \"depth\",\n",
    "    \"file_role\": \"depth_map_png16\",\n",
    "    \"bucket\": BUCKET,\n",
    "    \"path\": depth_png_path,\n",
    "    \"mime_type\": \"image/png\",\n",
    "    \"meta\": {\"encoding\":\"u16_rel\", \"model\":\"DA2_vitl\", \"tta\": True, \"input_size\": 896}\n",
    "}).execute()\n",
    "\n",
    "supabase.table(\"pipeline_outputs\").upsert({\n",
    "    \"run_id\": run_id,\n",
    "    \"stage\": \"depth\",\n",
    "    \"file_role\": \"depth_viz\",\n",
    "    \"bucket\": BUCKET,\n",
    "    \"path\": depth_viz_path,\n",
    "    \"mime_type\": \"image/jpeg\",\n",
    "    \"meta\": {\"colormap\":\"inferno\"}\n",
    "}).execute()\n",
    "\n",
    "print(\"OK depth outputs uploaded + DB rows\")\n",
    "print(\"RUN DONE:\", run_id)\n",
    "print(\"Input:\", input_path)\n",
    "print(\"Depth PNG:\", depth_png_path)\n",
    "print(\"Depth Viz:\", depth_viz_path)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
