{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24c2c12e",
   "metadata": {},
   "source": [
    "### Code (vitl model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562074a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using repo_root: /content/drive/MyDrive/Depthanythingv2/Depth-Anything-V2\n",
      "sys.path[0]: /content/drive/MyDrive/Depthanythingv2/Depth-Anything-V2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:dinov2:xFormers not available\n",
      "WARNING:dinov2:xFormers not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK import DepthAnythingV2\n"
     ]
    }
   ],
   "source": [
    "import sys, os, glob\n",
    "\n",
    "REPO = \"/content/drive/MyDrive/Depthanythingv2\"\n",
    "dirs = glob.glob(REPO + \"/**/depth_anything_v2\", recursive=True)\n",
    "\n",
    "if not dirs:\n",
    "    raise RuntimeError(\"Can't find depth_anything_v2 folder anywhere under REPO.\")\n",
    "\n",
    "module_dir = dirs[0]                      # .../depth_anything_v2\n",
    "repo_root = os.path.dirname(module_dir)   # the folder that CONTAINS depth_anything_v2\n",
    "\n",
    "if repo_root not in sys.path:\n",
    "    sys.path.insert(0, repo_root)\n",
    "\n",
    "print(\"Using repo_root:\", repo_root)\n",
    "print(\"sys.path[0]:\", sys.path[0])\n",
    "\n",
    "from depth_anything_v2.dpt import DepthAnythingV2\n",
    "print(\"OK import DepthAnythingV2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933bb580",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, sys, cv2, numpy as np, torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Your image folder on Drive\n",
    "IMG_DIR = \"/content/drive/MyDrive/Segmentation/dataset\"\n",
    "\n",
    "# Output folders (new)\n",
    "OUT_REL = \"/content/drive/MyDrive/Segmentation/depth-maps/raw_da2_vitl896_tta\"\n",
    "OUT_VIZ = \"/content/drive/MyDrive/Segmentation/depth-maps/viz_da2_vitl896_tta\"\n",
    "\n",
    "# DA2 repo path + checkpoint path\n",
    "REPO = \"/content/drive/MyDrive/Depthanythingv2\"\n",
    "CKPT = \"/content/drive/MyDrive/Depthanythingv2/checkpoints/depth_anything_v2_vitl.pth\"\n",
    "\n",
    "os.makedirs(OUT_REL, exist_ok=True)\n",
    "os.makedirs(OUT_VIZ, exist_ok=True)\n",
    "\n",
    "# Make sure we can import the library\n",
    "sys.path.append(REPO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebe5ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded vitl on cpu\n"
     ]
    }
   ],
   "source": [
    "from depth_anything_v2.dpt import DepthAnythingV2\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model_configs = {\n",
    "    'vitl': {'encoder': 'vitl', 'features': 256, 'out_channels': [256, 512, 1024, 1024]}\n",
    "}\n",
    "\n",
    "model = DepthAnythingV2(**model_configs['vitl'])\n",
    "state = torch.load(CKPT, map_location='cpu')\n",
    "model.load_state_dict(state, strict=True)\n",
    "model = model.to(DEVICE).eval()\n",
    "\n",
    "print(\"Loaded vitl on\", DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3040b045",
   "metadata": {},
   "outputs": [],
   "source": [
    "def letterbox(img, target=896):\n",
    "    h, w = img.shape[:2]\n",
    "    s = target / max(h, w)\n",
    "    nh, nw = int(round(h * s)), int(round(w * s))\n",
    "    img_r = cv2.resize(img, (nw, nh), interpolation=cv2.INTER_CUBIC)\n",
    "    top = (target - nh) // 2; bottom = target - nh - top\n",
    "    left = (target - nw) // 2; right = target - nw - left\n",
    "    img_p = cv2.copyMakeBorder(img_r, top, bottom, left, right, cv2.BORDER_CONSTANT, value=(0, 0, 0))\n",
    "    return img_p, (top, bottom, left, right), (h, w)\n",
    "\n",
    "def unletterbox(arr, pads, orig_hw):\n",
    "    top, bottom, left, right = pads\n",
    "    arr = arr[top:arr.shape[0]-bottom, left:arr.shape[1]-right]\n",
    "    return cv2.resize(arr, (orig_hw[1], orig_hw[0]), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "def infer_tta_rel(img_bgr):\n",
    "    # Predict and average normal + flipped; keep float32\n",
    "    d0 = model.infer_image(img_bgr).astype(np.float32)\n",
    "    d1 = model.infer_image(cv2.flip(img_bgr, 1)).astype(np.float32)\n",
    "    d1 = np.flip(d1, axis=1)\n",
    "    d = 0.5 * (d0 + d1)\n",
    "    return d.astype(np.float32)\n",
    "\n",
    "def to_u16_rel(depth):\n",
    "    d = depth.astype(np.float32)\n",
    "    d = np.nan_to_num(d, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    if (d > 0).sum() < 10:\n",
    "        return np.zeros_like(d, dtype=np.uint16)\n",
    "    p1, p99 = np.percentile(d[d > 0], (1, 99))\n",
    "    p1 = np.float32(p1); p99 = np.float32(p99)\n",
    "    d = np.clip(d, p1, p99)\n",
    "    d = (d - p1) / max(np.float32(1e-6), (p99 - p1))\n",
    "    d = np.clip(d, np.float32(1e-6), np.float32(1.0))   # avoid exact zeros\n",
    "    return (d * np.float32(65535.0)).astype(np.uint16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d384ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 563/563 [11:22:28<00:00, 72.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 563 depth maps to /content/drive/MyDrive/Segmentation/depth-maps/raw_da2_vitl896_tta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "paths = sorted(\n",
    "    p for ext in (\"*.jpg\",\"*.jpeg\",\"*.png\",\"*.JPG\",\"*.PNG\")\n",
    "    for p in glob.glob(os.path.join(IMG_DIR, ext))\n",
    ")\n",
    "\n",
    "for p in tqdm(paths):\n",
    "    img = cv2.imread(p)                    # uint8\n",
    "    img_p, pads, orig_hw = letterbox(img, 896)\n",
    "    depth_rel_p = infer_tta_rel(img_p)     # float32\n",
    "    depth_rel = unletterbox(depth_rel_p, pads, orig_hw).astype(np.float32)\n",
    "\n",
    "    rel16 = to_u16_rel(depth_rel)\n",
    "    stem = os.path.splitext(os.path.basename(p))[0]\n",
    "    cv2.imwrite(f\"{OUT_REL}/{stem}.png\", rel16)\n",
    "\n",
    "    viz = cv2.applyColorMap(255 - (rel16 // 256).astype(np.uint8), cv2.COLORMAP_INFERNO)\n",
    "    cv2.imwrite(f\"{OUT_VIZ}/{stem}.jpg\", viz)\n",
    "\n",
    "print(\"Saved\", len(paths), \"depth maps to\", OUT_REL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d5e07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls  /content/drive/MyDrive/Depthanythingv2/output-vitl/depths/raw_da2_vitl896_tta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53517a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, sys, cv2, numpy as np, torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ==== paths (same as yours) ====\n",
    "IMG_DIR = \"/content/drive/MyDrive/Depthanythingv2/data/eval\"\n",
    "OUT_REL = \"/content/drive/MyDrive/Depthanythingv2/output-vitl/depths/raw_da2_vitl896_1152_ms_tta4_jbf\"\n",
    "OUT_VIZ = \"/content/drive/MyDrive/Depthanythingv2/output-vitl/depths/viz_da2_vitl896_1152_ms_tta4_jbf\"\n",
    "REPO    = \"/content/drive/MyDrive/Depthanythingv2\"\n",
    "CKPT    = f\"{REPO}/checkpoints/depth_anything_v2_vitl.pth\"\n",
    "os.makedirs(OUT_REL, exist_ok=True); os.makedirs(OUT_VIZ, exist_ok=True)\n",
    "sys.path.append(REPO)\n",
    "\n",
    "from depth_anything_v2.dpt import DepthAnythingV2\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = DepthAnythingV2(encoder='vitl', features=256, out_channels=[256,512,1024,1024])\n",
    "state = torch.load(CKPT, map_location='cpu'); model.load_state_dict(state, strict=True)\n",
    "model = model.to(DEVICE).eval()\n",
    "print(\"Loaded vitl on\", DEVICE)\n",
    "\n",
    "# ---------- helpers ----------\n",
    "def letterbox_reflect(img, target):\n",
    "    h, w = img.shape[:2]\n",
    "    s = target / max(h, w)\n",
    "    nh, nw = int(round(h * s)), int(round(w * s))\n",
    "    img_r = cv2.resize(img, (nw, nh), interpolation=cv2.INTER_AREA if s < 1.0 else cv2.INTER_CUBIC)\n",
    "    top = (target - nh) // 2; bottom = target - nh - top\n",
    "    left = (target - nw) // 2; right = target - nw - left\n",
    "    img_p = cv2.copyMakeBorder(img_r, top, bottom, left, right, cv2.BORDER_REFLECT_101)\n",
    "    return img_p, (top, bottom, left, right), (h, w)\n",
    "\n",
    "def unletterbox(arr, pads, orig_hw):\n",
    "    top, bottom, left, right = pads\n",
    "    arr = arr[top:arr.shape[0]-bottom, left:arr.shape[1]-right]\n",
    "    return cv2.resize(arr, (orig_hw[1], orig_hw[0]), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "@torch.no_grad()\n",
    "def infer_one(img_bgr):\n",
    "    # model.infer_image accepts uint8 BGR; returns float32 depth (relative)\n",
    "    return model.infer_image(img_bgr).astype(np.float32)\n",
    "\n",
    "def infer_tta4(img_bgr):\n",
    "    # none, h, v, hv; unflip back and average\n",
    "    d0 = infer_one(img_bgr)\n",
    "    d1 = np.flip(infer_one(cv2.flip(img_bgr, 1)), axis=1)  # h\n",
    "    d2 = np.flip(infer_one(cv2.flip(img_bgr, 0)), axis=0)  # v\n",
    "    d3 = np.flip(np.flip(infer_one(cv2.flip(cv2.flip(img_bgr, 1), 0)), axis=1), axis=0)  # hv\n",
    "    return (d0 + d1 + d2 + d3) / 4.0\n",
    "\n",
    "def infer_ms_tta(img_bgr, sizes=(896, 1152)):\n",
    "    outs = []\n",
    "    for s in sizes:\n",
    "        img_p, pads, orig_hw = letterbox_reflect(img_bgr, s)\n",
    "        d = infer_tta4(img_p)\n",
    "        d = unletterbox(d, pads, orig_hw).astype(np.float32)\n",
    "        outs.append(d)\n",
    "    # resize all to original (already done) and average\n",
    "    return np.mean(outs, axis=0).astype(np.float32)\n",
    "\n",
    "def joint_bilateral_depth(depth, guide_bgr, ds=7, dr=0.1, iters=2):\n",
    "    # depth in [0,1] relative; guide is BGR uint8. Use domain transform-like iterative bilateral.\n",
    "    d = depth.copy().astype(np.float32)\n",
    "    g = guide_bgr\n",
    "    for _ in range(iters):\n",
    "        # OpenCV doesn't have true joint bilateral; use bilateral on depth plus small guidance mix\n",
    "        # Build an edge map to preserve discontinuities\n",
    "        edges = cv2.Canny(cv2.cvtColor(g, cv2.COLOR_BGR2GRAY), 50, 150).astype(np.float32)/255.0\n",
    "        # Light bilateral\n",
    "        d_blur = cv2.bilateralFilter(d, ds, dr*255.0, ds)\n",
    "        # Keep strong edges from original, smooth elsewhere\n",
    "        w = cv2.GaussianBlur(edges, (0,0), 1.0)\n",
    "        w = np.clip(1.0 - w, 0.0, 1.0).astype(np.float32)\n",
    "        d = w*d_blur + (1.0 - w)*d\n",
    "    return d\n",
    "\n",
    "def to_u16_rel(depth):\n",
    "    d = depth.astype(np.float32)\n",
    "    d = np.nan_to_num(d, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    if (d > 0).sum() < 10:\n",
    "        return np.zeros_like(d, dtype=np.uint16)\n",
    "    p_lo, p_hi = np.percentile(d[d > 0], (0.5, 99.5))\n",
    "    p_lo = np.float32(p_lo); p_hi = np.float32(p_hi)\n",
    "    d = np.clip((d - p_lo) / max(np.float32(1e-6), (p_hi - p_lo)), 0, 1)\n",
    "    return (d * np.float32(65535.0)).astype(np.uint16)\n",
    "\n",
    "# ---------- run ----------\n",
    "paths = sorted(p for ext in (\"*.jpg\",\"*.jpeg\",\"*.png\",\"*.JPG\",\"*.PNG\")\n",
    "               for p in glob.glob(os.path.join(IMG_DIR, ext)))\n",
    "\n",
    "for p in tqdm(paths):\n",
    "    img = cv2.imread(p)\n",
    "    depth_rel = infer_ms_tta(img, sizes=(896,1152))  # <- multi-scale + TTA(4)\n",
    "\n",
    "    # edge-preserving refinement guided by RGB to sharpen boundaries / flatten planes\n",
    "    x = depth_rel.copy()\n",
    "    # bring to [0,1] before refinement to stabilize bilateral behavior\n",
    "    if (x>0).sum() >= 10:\n",
    "        q1, q99 = np.percentile(x[x>0], (1,99))\n",
    "        x = np.clip((x - q1) / max(1e-6, (q99 - q1)), 0, 1).astype(np.float32)\n",
    "    x = joint_bilateral_depth(x, img, ds=7, dr=0.08, iters=2)\n",
    "    depth_rel = x.astype(np.float32)\n",
    "\n",
    "    stem = os.path.splitext(os.path.basename(p))[0]\n",
    "    rel16 = to_u16_rel(depth_rel)\n",
    "    cv2.imwrite(f\"{OUT_REL}/{stem}.png\", rel16)\n",
    "\n",
    "    viz = cv2.applyColorMap(255 - (rel16 // 256).astype(np.uint8), cv2.COLORMAP_INFERNO)\n",
    "    cv2.imwrite(f\"{OUT_VIZ}/{stem}.jpg\", viz)\n",
    "\n",
    "print(\"Saved\", len(paths), \"depth maps to\", OUT_REL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912fea1f",
   "metadata": {},
   "source": [
    "### Evaluation (vitl model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86b2c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, cv2, numpy as np, pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- paths: point DEP_DIR to your vitl outputs ---\n",
    "IMG_DIR    = \"/content/drive/MyDrive/Depthanythingv2/data/eval\"\n",
    "DEP_DIR    = \"/content/drive/MyDrive/Depthanythingv2/output-vitl/depths/raw_da2_vitl896_1152_ms_tta4_jbf\"\n",
    "REPORT_CSV = \"/content/drive/MyDrive/Depthanythingv2/output-vitl/depth_eval_report_vitl896_1152_ms_tta4_jbf.csv\"\n",
    "os.makedirs(os.path.dirname(REPORT_CSV), exist_ok=True)\n",
    "\n",
    "# --- helpers ---\n",
    "def read_depth_rel(path_png16):\n",
    "    d16 = cv2.imread(path_png16, -1).astype(np.float32)\n",
    "    d = d16 / np.float32(65535.0)\n",
    "    d[~np.isfinite(d)] = np.nan\n",
    "    return d.astype(np.float32)\n",
    "\n",
    "def sobel_grad(a):\n",
    "    a = np.asarray(a, dtype=np.float32)\n",
    "    gx = cv2.Sobel(a, cv2.CV_32F, 1, 0, ksize=3)\n",
    "    gy = cv2.Sobel(a, cv2.CV_32F, 0, 1, ksize=3)\n",
    "    return np.sqrt(gx*gx + gy*gy).astype(np.float32)\n",
    "\n",
    "def edge_metrics(rgb, depth_rel):\n",
    "    g = cv2.cvtColor(rgb, cv2.COLOR_BGR2GRAY).astype(np.float32)/255.0\n",
    "    g = cv2.GaussianBlur(g,(3,3),0.8).astype(np.float32)\n",
    "    e_img = sobel_grad(g)\n",
    "\n",
    "    x = depth_rel.astype(np.float32)\n",
    "    x[np.isnan(x)] = 0.0\n",
    "    if (x>0).sum() < 10:\n",
    "        return 0.0, 0.0, 0.0\n",
    "    p1,p99 = np.percentile(x[x>0], (1,99))\n",
    "    p1 = np.float32(p1); p99 = np.float32(p99)\n",
    "    x = np.clip((x - p1) / max(np.float32(1e-6), (p99 - p1)), 0, 1).astype(np.float32)\n",
    "    e_dep = sobel_grad(x)\n",
    "\n",
    "    t1 = np.float32(np.percentile(e_img, 88))\n",
    "    t2 = np.float32(np.percentile(e_dep, 88))\n",
    "    E1 = (e_img >= t1).astype(np.uint8)\n",
    "    E2 = (e_dep >= t2).astype(np.uint8)\n",
    "\n",
    "    inter = (E1 & E2).sum()\n",
    "    prec  = inter / (E2.sum() + 1e-6)\n",
    "    rec   = inter / (E1.sum() + 1e-6)\n",
    "    f1    = 2*prec*rec / max(1e-6, (prec+rec))\n",
    "    return float(prec), float(rec), float(f1)\n",
    "\n",
    "def planarity(depth_rel):\n",
    "    z = depth_rel.astype(np.float32)\n",
    "    mask = np.isfinite(z) & (z>0)\n",
    "    if mask.sum() < 1000:\n",
    "        return np.nan\n",
    "    ys,xs = np.where(mask)\n",
    "    sel = np.random.choice(len(xs), size=min(20000,len(xs)), replace=False)\n",
    "    xs,ys = xs[sel],ys[sel]; zz = z[ys,xs].astype(np.float32)\n",
    "\n",
    "    H,W = z.shape; f = np.float32(1.2*max(W,H)); cx = np.float32(W/2); cy = np.float32(H/2)\n",
    "    X = (xs.astype(np.float32) - cx)*zz/f\n",
    "    Y = (ys.astype(np.float32) - cy)*zz/f\n",
    "    P = np.stack([X,Y,zz],1).astype(np.float32)\n",
    "\n",
    "    best=None; rng = np.random.default_rng(0)\n",
    "    for _ in range(100):\n",
    "        i = rng.choice(len(P), 3, replace=False)\n",
    "        v1 = P[i[1]] - P[i[0]]; v2 = P[i[2]] - P[i[0]]\n",
    "        n  = np.cross(v1, v2).astype(np.float32)\n",
    "        n_norm = np.linalg.norm(n)\n",
    "        if n_norm < 1e-8: continue\n",
    "        n /= n_norm; d0 = -np.dot(n, P[i[0]]).astype(np.float32)\n",
    "        dist = np.abs(P @ n + d0).astype(np.float32)\n",
    "        rmse = float(np.sqrt(np.mean(dist**2)))\n",
    "        if (best is None) or (rmse < best): best = rmse\n",
    "    if best is None: return np.nan\n",
    "    med = float(np.median(zz[zz>0])) if np.any(zz>0) else 1.0\n",
    "    return float(best / max(1e-6, med))\n",
    "\n",
    "def invalid_ratio(depth_rel):\n",
    "    return float(np.isnan(depth_rel).mean())\n",
    "\n",
    "# --- compute rows ---\n",
    "rows = []\n",
    "img_paths = sorted(p for ext in (\"*.jpg\",\"*.jpeg\",\"*.png\",\"*.JPG\",\"*.PNG\")\n",
    "                   for p in glob.glob(os.path.join(IMG_DIR, ext)))\n",
    "\n",
    "for p_rgb in tqdm(img_paths):\n",
    "    stem = os.path.splitext(os.path.basename(p_rgb))[0]\n",
    "    p_dep = os.path.join(DEP_DIR, f\"{stem}.png\")\n",
    "    if not os.path.exists(p_dep):\n",
    "        continue\n",
    "    rgb   = cv2.imread(p_rgb)\n",
    "    depth = read_depth_rel(p_dep)\n",
    "    prec, rec, f1 = edge_metrics(rgb, depth)\n",
    "    plan = planarity(depth)\n",
    "    inv  = invalid_ratio(depth)\n",
    "    rows.append([stem, prec, rec, f1, plan, inv])\n",
    "\n",
    "df = pd.DataFrame(rows, columns=[\n",
    "    \"img_id\",\"edge_prec\",\"edge_rec\",\"edge_f1\",\"planarity_residual_rel\",\"invalid_ratio\"\n",
    "])\n",
    "\n",
    "if df.empty:\n",
    "    raise RuntimeError(f\"No matches found. Check DEP_DIR: {DEP_DIR}\")\n",
    "\n",
    "# --- vectorized overall score ---\n",
    "f1   = df[\"edge_f1\"].astype(float).fillna(0.0)\n",
    "plan = df[\"planarity_residual_rel\"].astype(float).fillna(0.1)\n",
    "inv  = df[\"invalid_ratio\"].astype(float).fillna(0.0)\n",
    "plan_ok = np.clip(1.0 - (plan/0.1), 0.0, 1.0)\n",
    "inv_ok  = np.clip(1.0 - (inv /0.05), 0.0, 1.0)\n",
    "df[\"overall_score\"] = 0.6*f1 + 0.25*plan_ok + 0.15*inv_ok\n",
    "\n",
    "df.to_csv(REPORT_CSV, index=False)\n",
    "print(f\"Average overall_score = {df['overall_score'].mean():.3f} ± {df['overall_score'].std():.3f}\")\n",
    "df.sort_values(\"overall_score\", ascending=False).head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f33c0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"/content/drive/MyDrive/Depthanythingv2/output-vitl/depth_eval_report_vitl896_tta.csv\")\n",
    "mean = df[\"overall_score\"].mean()\n",
    "std = df[\"overall_score\"].std()\n",
    "print(f\"Average overall_score = {mean:.3f} ± {std:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7be4fb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
